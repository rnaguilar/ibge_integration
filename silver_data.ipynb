{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c19eb0",
   "metadata": {},
   "source": [
    "# Instanciar Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f9578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações do PySpark e SQLalchemy\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import col, from_json, explode, expr, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType\n",
    "from pyspark.sql import SparkSession\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "import psycopg2\n",
    "\n",
    "# Configuração da sessão Spark\n",
    "spark_session = SparkSession.builder \\\n",
    "    .appName(\"Ibge_silver\") \\\n",
    "    .config(\"spark.master\", \"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.7.1\") \\\n",
    "    .config(\"spark.executor.instances\", \"3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc0503",
   "metadata": {},
   "source": [
    "# PANDAS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1e5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_upsert(table, conn, keys, data_iter):\n",
    "    \"\"\"\n",
    "    Função para atualizar os dados na tabela usando a lógica de upsert.\n",
    "\n",
    "    Args:\n",
    "        table (sqlalchemy.Table): Tabela alvo para upsert.\n",
    "        conn (sqlalchemy.engine.Connection): Conexão com o banco de dados.\n",
    "        keys (list): Lista das chaves da tabela.\n",
    "        data_iter (iterable): Iterável contendo dados a serem inseridos/atualizados.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Example:\n",
    "        keys = ['id', 'name']\n",
    "        data_iter = [(1, 'John'), (2, 'Jane')]\n",
    "\n",
    "        # Tabela alvo 'users' com colunas 'id' e 'name'\n",
    "        users_table = sqlalchemy.Table('users', metadata, autoload_with=engine)\n",
    "\n",
    "        # Conexão com o banco de dados\n",
    "        db_conn = engine.connect()\n",
    "\n",
    "        # Chamada à função de upsert\n",
    "        call_upsert(users_table, db_conn, keys, data_iter)\n",
    "\n",
    "        # Fechar a conexão\n",
    "        db_conn.close()\n",
    "    \"\"\"\n",
    "    data = [dict(zip(keys, row)) for row in data_iter]\n",
    "\n",
    "    # Construir a declaração de inserção\n",
    "    insert_statement = insert(table).values(data)\n",
    "\n",
    "    # Construir a declaração de upsert\n",
    "    upsert_statement = insert_statement.on_conflict_do_update(\n",
    "        constraint=f\"{table.name}_pkey\",\n",
    "        set_={c.key: c for c in insert_statement.excluded},\n",
    "    )\n",
    "\n",
    "    # Executar a declaração de upsert\n",
    "    conn.execute(upsert_statement)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e5f84",
   "metadata": {},
   "source": [
    "# SQL CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85383ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações de conexão com o PostgreSQL\n",
    "# Este item é totalmente editável, para uma conexão de sua preferência (Vamos fazer conforme o docker-compose que subimos)\n",
    "\n",
    "host = 'localhost'\n",
    "port = '8085'\n",
    "\n",
    "bronze_url = f\"jdbc:postgresql://{host}:{port}/bronze_data\"\n",
    "silver_url = f\"jdbc:postgresql://{host}:{port}/silver_data\"\n",
    "properties = {\"user\": \"ibge\", \"password\": \"ibge\", \"driver\": \"org.postgresql.Driver\"}\n",
    "\n",
    "# Criar um engine do SQLAlchemy\n",
    "bronze_engine = create_engine(f\"postgresql://{properties['user']}:{properties['password']}@{host}:{port}/bronze_data\")\n",
    "silver_engine = create_engine(f\"postgresql://{properties['user']}:{properties['password']}@{host}:{port}/silver_data\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb8379",
   "metadata": {},
   "source": [
    "# REIGAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e291ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceção subject table for an INSERT, UPDATE or DELETE expected, got <pandas.io.sql.SQLTable object at 0x000001E6CBC76000>.\n"
     ]
    }
   ],
   "source": [
    "# INSERÇÃO DA DIMENSÃO REGIÃO USANDO PANDAS\n",
    "\n",
    "# Definir a consulta SQL\n",
    "query = 'SELECT id_regiao,  regiao FROM public.regiao'\n",
    "\n",
    "\n",
    "# Upinset dos dados via pandas a cada 10000 linhas\n",
    "for data_frame in pd.read_sql(query,bronze_engine,chunksize=10000):\n",
    "    try:\n",
    "        pd.DataFrame(data_frame).to_sql(\n",
    "            'regiao', \n",
    "            silver_engine, \n",
    "            schema='public', \n",
    "            index=False, \n",
    "            if_exists=\"append\", \n",
    "            method=call_upsert\n",
    "        )\n",
    "        print(\"UpInsert executado\")\n",
    "    except Exception as e :\n",
    "        print(f'Exceção {str(e)}')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5edc0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceção subject table for an INSERT, UPDATE or DELETE expected, got <pandas.io.sql.SQLTable object at 0x000001E6CA3AF6B0>.\n"
     ]
    }
   ],
   "source": [
    "# INSERÇÃO DA DIMENSÃO ESTADO USANDO PANDAS\n",
    "\n",
    "# Definir a consulta SQL\n",
    "query = \"\"\"\n",
    "select\n",
    "\tid_estado,\n",
    "\tuf,\n",
    "\testado,\n",
    "\t1 as latitude,\n",
    "\t1 as longitude,\n",
    "\tid_regiao as id_regiao\n",
    "from\n",
    "\tpublic.estado\"\"\"\n",
    "\n",
    "# Upinset dos dados via pandas a cada 10000 linhas\n",
    "for data_frame in pd.read_sql(query,bronze_engine,chunksize=10000):\n",
    "    try:\n",
    "        pd.DataFrame(data_frame).to_sql(\n",
    "            'estado', \n",
    "            silver_engine, \n",
    "            schema='public', \n",
    "            index=False, \n",
    "            if_exists=\"append\", \n",
    "            method=call_upsert\n",
    "        )\n",
    "        print(\"UpInsert executado\")\n",
    "    except Exception as e :\n",
    "        print(f'Exceção {str(e)}')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c5e09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceção subject table for an INSERT, UPDATE or DELETE expected, got <pandas.io.sql.SQLTable object at 0x000001E6CBC77470>.\n"
     ]
    }
   ],
   "source": [
    "# INSERÇÃO DA DIMENSÃO ESTADO USANDO PANDAS\n",
    "\n",
    "\n",
    "# Definir a consulta SQL\n",
    "sql_municipio = \"\"\"\n",
    "    select\n",
    "\tm.*,\n",
    "\tcase when c.capital is not null then true else false end as flag_capital\n",
    "from\n",
    "\tpublic.capitais c\n",
    "right join\n",
    "\tmunicipios m \n",
    "\ton\n",
    "\tc.uf = m.uf\n",
    "\tand c.capital = m.municipio\n",
    "\"\"\"\n",
    "\n",
    "# Upinset dos dados via pandas a cada 10000 linhas\n",
    "for data_frame in pd.read_sql(sql_municipio,bronze_engine,chunksize=10000):\n",
    "    try:\n",
    "        pd.DataFrame(data_frame).to_sql(\n",
    "            'municipio', \n",
    "            silver_engine, \n",
    "            schema='public', \n",
    "            index=False, \n",
    "            if_exists=\"append\", \n",
    "            method=call_upsert\n",
    "        )\n",
    "        print(\"UpInsert executado\")\n",
    "    except Exception as e :\n",
    "        print(f'Exceção {str(e)}')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74c9cd3",
   "metadata": {},
   "source": [
    "# PESQUISAS (leitura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b2ae729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+----+-----+\n",
      "|cd_pesquisa|municipio|cd_estado| ano|valor|\n",
      "+-----------+---------+---------+----+-----+\n",
      "|      30255|  2927408|       29|1991|0.386|\n",
      "|      30255|  2927408|       29|2000|0.512|\n",
      "|      30255|  5103403|       51|1991|0.449|\n",
      "|      30255|  5103403|       51|2000|0.601|\n",
      "|      30255|  3304557|       33|1991|0.573|\n",
      "|      30255|  3304557|       33|2000|0.664|\n",
      "|      30255|  3304557|       33|2010|0.761|\n",
      "|      30255|  3304557|       33|2012|0.762|\n",
      "|      30255|  3304557|       33|2013|0.768|\n",
      "|      30255|  3304557|       33|2014| 0.78|\n",
      "|      30255|  3304557|       33|2015|0.785|\n",
      "|      30255|  3304557|       33|2016|0.789|\n",
      "|      30255|  3304557|       33|2017|0.791|\n",
      "|      30255|  3304557|       33|2018|0.805|\n",
      "|      30255|  3304557|       33|2019|0.809|\n",
      "|      30255|  3304557|       33|2020|0.785|\n",
      "|      30255|  3304557|       33|2021|0.762|\n",
      "|      30255|  2800308|       28|1991|0.408|\n",
      "|      30255|  1600303|       16|1991|0.472|\n",
      "|      30255|  1600303|       16|2000|0.577|\n",
      "+-----------+---------+---------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IDH\n",
    "\n",
    "# leitura dos dados via odbc\n",
    "df_pesquisas_idh = spark_session.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", bronze_url) \\\n",
    "    .option(\"driver\", properties[\"driver\"]) \\\n",
    "    .option(\"dbtable\", \"pesquisas_idh\") \\\n",
    "    .option(\"user\", properties[\"user\"]) \\\n",
    "    .option(\"password\", properties[\"password\"]) \\\n",
    "    .load()\n",
    "\n",
    "# Definir a consulta SQL\n",
    "sql_query = \"\"\"\n",
    "    select\n",
    "\te.id_estado ,\n",
    "\tm.id_municipio as id_capital\n",
    "from\n",
    "\tpublic.capitais c\n",
    "inner join\n",
    "\tmunicipios m \n",
    "on\n",
    "\tc.uf = m.uf\n",
    "\tand c.capital = m.municipio\n",
    "inner join\n",
    "\tpublic.estado e \n",
    "on\n",
    "\tc.uf  = e.uf \n",
    "\"\"\"\n",
    "\n",
    "# Ler os dados do banco de dados usando Spark\n",
    "df_estado_municipio = spark_session.read.jdbc(url=bronze_url, table=f\"({sql_query}) as subquery\", properties=properties)\n",
    "\n",
    "\n",
    "# Realize o left join\n",
    "df_idh_final = df_pesquisas_idh.join(\n",
    "    df_estado_municipio,\n",
    "    df_pesquisas_idh[\"cd_estado\"] == df_estado_municipio[\"id_estado\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# seleciona os dados aplicando os tipos\n",
    "df_idh_final = df_idh_final.select(\n",
    "    col('cd_pesquisa').astype(StringType()),\n",
    "    col('id_capital').alias('municipio').astype(IntegerType()),\n",
    "    col('cd_estado').astype(IntegerType()),\n",
    "    col('ano').astype(IntegerType()),\n",
    "    col('valor').astype(StringType())\n",
    ")\n",
    "\n",
    "# Mostrar o DataFrame resultante\n",
    "df_idh_final.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee89d8dc-0fb3-4bcf-b91d-7f544544c21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+----+------+\n",
      "|cd_pesquisa|municipio|cd_estado| ano| valor|\n",
      "+-----------+---------+---------+----+------+\n",
      "|  9324_6579|  3500105|     NULL|2018| 35023|\n",
      "|  9324_6579|  3500204|     NULL|2018|  3571|\n",
      "|  9324_6579|  3500303|     NULL|2018| 35954|\n",
      "|  9324_6579|  3500402|     NULL|2018|  8137|\n",
      "|  9324_6579|  3500501|     NULL|2018| 18599|\n",
      "|  9324_6579|  3500550|     NULL|2018|  6040|\n",
      "|  9324_6579|  3500600|     NULL|2018|  3380|\n",
      "|  9324_6579|  3500709|     NULL|2018| 37023|\n",
      "|  9324_6579|  3500758|     NULL|2018|  5918|\n",
      "|  9324_6579|  3500808|     NULL|2018|  4147|\n",
      "|  9324_6579|  3500907|     NULL|2018|  4134|\n",
      "|  9324_6579|  3501004|     NULL|2018| 16164|\n",
      "|  9324_6579|  3501103|     NULL|2018|  4110|\n",
      "|  9324_6579|  3501152|     NULL|2018| 18484|\n",
      "|  9324_6579|  3501202|     NULL|2018|  3712|\n",
      "|  9324_6579|  3501301|     NULL|2018| 24830|\n",
      "|  9324_6579|  3501400|     NULL|2018|  5179|\n",
      "|  9324_6579|  3501509|     NULL|2018|  3206|\n",
      "|  9324_6579|  3501608|     NULL|2018|237112|\n",
      "|  9324_6579|  3501707|     NULL|2018| 39962|\n",
      "+-----------+---------+---------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# POPULACAO\n",
    "\n",
    "# leitura dos dados via odbc\n",
    "df_pesquisas_populacao = spark_session.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", bronze_url) \\\n",
    "    .option(\"driver\", properties[\"driver\"]) \\\n",
    "    .option(\"dbtable\", \"pesquisas_populacao\") \\\n",
    "    .option(\"user\", properties[\"user\"]) \\\n",
    "    .option(\"password\", properties[\"password\"]) \\\n",
    "    .load()\n",
    "\n",
    "\n",
    "# seleciona os dados aplicando os tipos\n",
    "df_pesquisas_populacao = df_pesquisas_populacao.select(\n",
    "    col('cd_pesquisa').astype(StringType()),\n",
    "    col('municipio').astype(IntegerType()),\n",
    "    lit(None).alias('cd_estado').astype(IntegerType()),\n",
    "    col('ano').astype(IntegerType()),\n",
    "    col('valor').astype(StringType())\n",
    ")\n",
    "\n",
    "# Mostrar o DataFrame resultante\n",
    "df_pesquisas_populacao.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da358ad-51b6-4bc3-8f24-bceae1bd8fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+----+--------+\n",
      "|cd_pesquisa|municipio|cd_estado| ano|   valor|\n",
      "+-----------+---------+---------+----+--------+\n",
      "|    37_5938|  3500105|     NULL|2019| 1191134|\n",
      "|    37_5938|  3500204|     NULL|2019|  112493|\n",
      "|    37_5938|  3500303|     NULL|2019| 1046725|\n",
      "|    37_5938|  3500402|     NULL|2019|  172428|\n",
      "|    37_5938|  3500501|     NULL|2019|  530696|\n",
      "|    37_5938|  3500550|     NULL|2019|  174587|\n",
      "|    37_5938|  3500600|     NULL|2019|  146025|\n",
      "|    37_5938|  3500709|     NULL|2019| 2146823|\n",
      "|    37_5938|  3500758|     NULL|2019|  105393|\n",
      "|    37_5938|  3500808|     NULL|2019|   87021|\n",
      "|    37_5938|  3500907|     NULL|2019|   90689|\n",
      "|    37_5938|  3501004|     NULL|2019|  536419|\n",
      "|    37_5938|  3501103|     NULL|2019|  121525|\n",
      "|    37_5938|  3501152|     NULL|2019| 2306521|\n",
      "|    37_5938|  3501202|     NULL|2019|  101240|\n",
      "|    37_5938|  3501301|     NULL|2019|  547949|\n",
      "|    37_5938|  3501400|     NULL|2019|   50648|\n",
      "|    37_5938|  3501509|     NULL|2019|   50661|\n",
      "|    37_5938|  3501608|     NULL|2019|11861436|\n",
      "|    37_5938|  3501707|     NULL|2019|  952230|\n",
      "+-----------+---------+---------+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PIB\n",
    "\n",
    "# leitura dos dados via odbc\n",
    "df_pesquisas_pib = spark_session.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", bronze_url) \\\n",
    "    .option(\"driver\", properties[\"driver\"]) \\\n",
    "    .option(\"dbtable\", \"pesquisas_pib\") \\\n",
    "    .option(\"user\", properties[\"user\"]) \\\n",
    "    .option(\"password\", properties[\"password\"]) \\\n",
    "    .load()\n",
    "\n",
    "# seleciona os dados aplicando os tipos\n",
    "df_pesquisas_pib = df_pesquisas_pib.select(\n",
    "    col('cd_pesquisa').astype(StringType()),\n",
    "    col('municipio').astype(IntegerType()),\n",
    "    lit(None).alias('cd_estado').astype(IntegerType()),\n",
    "    col('ano').astype(IntegerType()),\n",
    "    col('valor').astype(StringType())\n",
    ")\n",
    "\n",
    "# Mostrar o DataFrame resultante\n",
    "df_pesquisas_pib.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840680d3",
   "metadata": {},
   "source": [
    "# Pesquisas (Tratamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb820a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une todas as pesquisas\n",
    "df_pesquisas = df_pesquisas_populacao.union(df_idh_final).union(df_pesquisas_pib)\n",
    "\n",
    "# Grava as pesquias no banco\n",
    "df_pesquisas.write.format(\"jdbc\").option(\"url\", silver_url) \\\n",
    ".option(\"user\", \"ibge\") \\\n",
    ".option(\"password\", \"ibge\") \\\n",
    ".option(\"dbtable\", \"public.pesquisas\") \\\n",
    ".option(\"truncate\", True) \\\n",
    ".mode('overwrite') \\\n",
    ".save()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
