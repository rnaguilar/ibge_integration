{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c19eb0",
   "metadata": {},
   "source": [
    "# Instanciar Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f9578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import col, from_json , explode, expr, lit, when\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType\n",
    "from pyspark.sql import SparkSession\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "spark_session = SparkSession.builder \\\n",
    "    .appName(\"Ibge_silver\") \\\n",
    "    .config(\"spark.master\", \"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.7.1\") \\\n",
    "    .config(\"spark.executor.instances\", \"3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc0503",
   "metadata": {},
   "source": [
    "# PANDAS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d1e5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_upsert(table, conn, keys, data_iter):\n",
    "\n",
    "    data = [dict(zip(keys, row)) for row in data_iter]\n",
    "\n",
    "    insert_statement = insert(table.table).values(data)\n",
    "    upsert_statement = insert_statement.on_conflict_do_update(\n",
    "        constraint=f\"{table.table.name}_pkey\",\n",
    "        set_={c.key: c for c in insert_statement.excluded},\n",
    "    )\n",
    "\n",
    "    conn.execute(upsert_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e5f84",
   "metadata": {},
   "source": [
    "# SQL CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85383ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações de conexão com o PostgreSQL\n",
    "# Este item é totalmente editavel, para uma conexão de sua preferencia (Vamos fazer conforme o docker-compose que subimos)\n",
    "\n",
    "host = 'localhost'\n",
    "port = '8085'\n",
    "\n",
    "gold_url = f\"jdbc:postgresql://{host}:{port}/gold_data\"\n",
    "silver_url = f\"jdbc:postgresql://{host}:{port}/silver_data\"\n",
    "properties = {\"user\": \"ibge\", \"password\": \"ibge\", \"driver\": \"org.postgresql.Driver\"}\n",
    "\n",
    "# Criar um engine do SQLAlchemy\n",
    "gold_engine = create_engine(f\"postgresql://{properties['user']}:{properties['password']}@{host}:{port}/gold_data\")\n",
    "silver_engine = create_engine(f\"postgresql://{properties['user']}:{properties['password']}@{host}:{port}/silver_data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb8379",
   "metadata": {},
   "source": [
    "# REIGAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e291ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UpInsert executado\n"
     ]
    }
   ],
   "source": [
    "# INSERÇÃO DA DIMENSÃO REGIÃO USANDO PANDAS\n",
    "\n",
    "query = 'SELECT * FROM public.regiao'\n",
    "\n",
    "for data_frame in pd.read_sql(query,silver_engine,chunksize=10000):\n",
    "    try:\n",
    "        pd.DataFrame(data_frame).to_sql(\n",
    "            'regiao', \n",
    "            gold_engine, \n",
    "            schema='public', \n",
    "            index=False, \n",
    "            if_exists=\"append\", \n",
    "            method=call_upsert\n",
    "        )\n",
    "        print(\"UpInsert executado\")\n",
    "    except Exception as e :\n",
    "        print(f'Exceção {str(e)}')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5edc0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UpInsert executado\n"
     ]
    }
   ],
   "source": [
    "# INSERÇÃO DA DIMENSÃO ESTADO USANDO PANDAS\n",
    "\n",
    "query = \"\"\"\n",
    "select\n",
    "\t*\n",
    "from\n",
    "\tpublic.estado\"\"\"\n",
    "\n",
    "for data_frame in pd.read_sql(query,silver_engine,chunksize=10000):\n",
    "    try:\n",
    "        pd.DataFrame(data_frame).to_sql(\n",
    "            'estado', \n",
    "            gold_engine, \n",
    "            schema='public', \n",
    "            index=False, \n",
    "            if_exists=\"append\", \n",
    "            method=call_upsert\n",
    "        )\n",
    "        print(\"UpInsert executado\")\n",
    "    except Exception as e :\n",
    "        print(f'Exceção {str(e)}')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c5e09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UpInsert executado\n"
     ]
    }
   ],
   "source": [
    "# INSERÇÃO DA DIMENSÃO ESTADO USANDO PANDAS\n",
    "\n",
    "sql_municipio = \"\"\"\n",
    "    select\n",
    "\tid_municipio,\n",
    "\tmunicipio,\n",
    "\tuf,\n",
    "\tflag_capital\n",
    "from\n",
    "\tpublic.municipio;\n",
    "\"\"\"\n",
    "for data_frame in pd.read_sql(sql_municipio,silver_engine,chunksize=10000):\n",
    "    try:\n",
    "        pd.DataFrame(data_frame).to_sql(\n",
    "            'municipio', \n",
    "            gold_engine, \n",
    "            schema='public', \n",
    "            index=False, \n",
    "            if_exists=\"append\", \n",
    "            method=call_upsert\n",
    "        )\n",
    "        print(\"UpInsert executado\")\n",
    "    except Exception as e :\n",
    "        print(f'Exceção {str(e)}')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "530525b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lat e long\n",
    "\n",
    "coordenadas = {\n",
    "\t'AC': [-8.77, -70.55],\n",
    "\t'AL': [-9.62, -36.82],\n",
    "\t'AM': [-3.47, -65.10],\n",
    "\t'AP': [1.41, -51.77],\n",
    "\t'BA': [-13.29, -41.71],\n",
    "\t'CE': [-5.20, -39.53],\n",
    "\t'DF': [-15.83, -47.86],\n",
    "\t'ES': [-19.19, -40.34],\n",
    "\t'GO': [-15.98, -49.86],\n",
    "\t'MA': [-5.42, -45.44],\n",
    "\t'MT': [-12.64, -55.42],\n",
    "\t'MS': [-20.51, -54.54],\n",
    "\t'MG': [-18.10, -44.38],\n",
    "\t'PA': [-3.79, -52.48],\n",
    "\t'PB': [-7.28, -36.72],\n",
    "\t'PR': [-24.89, -51.55],\n",
    "\t'PE': [-8.38, -37.86],\n",
    "\t'PI': [-6.60, -42.28],\n",
    "\t'RJ': [-22.25, -42.66],\n",
    "\t'RN': [-5.81, -36.59],\n",
    "\t'RO': [-10.83, -63.34],\n",
    "\t'RS': [-30.17, -53.50],\n",
    "\t'RR': [1.99, -61.33],\n",
    "\t'SC': [-27.45, -50.95],\n",
    "\t'SE': [-10.57, -37.45],\n",
    "\t'SP': [-22.19, -48.79],\n",
    "\t'TO': [-9.46, -48.26]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(list(coordenadas.items()), columns=['UF', 'Coords'])\n",
    "df[['lat', 'long']] = pd.DataFrame(df['Coords'].tolist(), index=df.index)\n",
    "\n",
    "# Descartar a coluna original \"Coords\"\n",
    "df = df.drop('Coords', axis=1)\n",
    "\n",
    "df.to_sql(\n",
    "            'lat_long', \n",
    "            gold_engine, \n",
    "            schema='public', \n",
    "            index=False, \n",
    "            if_exists=\"replace\"\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74c9cd3",
   "metadata": {},
   "source": [
    "# PESQUISAS (leitura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b2ae729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+----+----------+------------+-------------------+\n",
      "| ano|municipio| idh|       pib|populacional| Faixa de População|\n",
      "+----+---------+----+----------+------------+-------------------+\n",
      "|2018|  1100015|NULL|  498980.0|       23167|Entre 11414 e 24725|\n",
      "|2018|  1100023|NULL| 2464704.0|      106168|    Maior que 24725|\n",
      "|2018|  1100031|NULL|  140503.0|        5438| Entre 5366 e 11414|\n",
      "|2018|  1100049|NULL| 2175840.0|       84813|    Maior que 24725|\n",
      "|2018|  1100056|NULL|  470647.0|       16444|Entre 11414 e 24725|\n",
      "|2018|  1100064|NULL|  330232.0|       16227|Entre 11414 e 24725|\n",
      "|2018|  1100072|NULL|  320416.0|        7567| Entre 5366 e 11414|\n",
      "|2018|  1100080|NULL|  230151.0|       17855|Entre 11414 e 24725|\n",
      "|2018|  1100098|NULL|  606072.0|       32047|    Maior que 24725|\n",
      "|2018|  1100106|NULL|  837459.0|       45783|    Maior que 24725|\n",
      "|2018|  1100114|NULL| 1484555.0|       51933|    Maior que 24725|\n",
      "|2018|  1100122|NULL| 3466810.0|      127907|    Maior que 24725|\n",
      "|2018|  1100130|NULL|  642283.0|       39097|    Maior que 24725|\n",
      "|2018|  1100148|NULL|  345779.0|       20459|Entre 11414 e 24725|\n",
      "|2018|  1100155|NULL|  807497.0|       36340|    Maior que 24725|\n",
      "|2018|  1100189|NULL| 1129770.0|       36434|    Maior que 24725|\n",
      "|2018|  1100205|0.73|1.665567E7|      519531|    Maior que 24725|\n",
      "|2018|  1100254|NULL|  418683.0|       19409|Entre 11414 e 24725|\n",
      "|2018|  1100262|NULL|  102476.0|        3723|     Entre 0 e 5366|\n",
      "|2018|  1100288|NULL| 1291476.0|       54702|    Maior que 24725|\n",
      "+----+---------+----+----------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IDH\n",
    "\n",
    "# Definir a consulta SQL\n",
    "sql_query = \"\"\"\n",
    "    select\n",
    "\tano,\n",
    "\tmunicipio,\n",
    "\ttp.pesquisa  as pesquisa ,\n",
    "\tvalor\n",
    "from\n",
    "\tpublic.pesquisas p\n",
    "left join\n",
    "\ttipo_pesquisa tp \n",
    "on\n",
    "\tp.cd_pesquisa  = tp.cd_pesquisa \n",
    "where\n",
    "\tp.ano in (2018,2019,2020,2021)\n",
    "\"\"\"\n",
    "\n",
    "# Ler os dados do banco de dados usando Spark\n",
    "df_pesquisa = spark_session.read.jdbc(url=silver_url, table=f\"({sql_query}) as subquery\", properties=properties)\n",
    "\n",
    "df_pivotado = df_pesquisa.groupBy(\"ano\", \"municipio\") \\\n",
    "    .pivot(\"pesquisa\") \\\n",
    "    .agg({\"valor\": \"first\"})\n",
    "\n",
    "# df_pivotado.show()\n",
    "\n",
    "df_pesquisa_final = df_pivotado.select(\n",
    "    col('ano'),\n",
    "    col('municipio'),\n",
    "    col('idh').astype(DoubleType()),\n",
    "    col('pib').astype(DoubleType()),\n",
    "    col('populacional').astype(IntegerType())\n",
    ")\n",
    "\n",
    "# Calcular quartis da coluna de população\n",
    "quartis = df_pesquisa_final.approxQuantile(\"populacional\", [0.25, 0.5, 0.75], 0.01)\n",
    "\n",
    "# Definir os limites dos quadrantes com base nos quartis\n",
    "limite_quadrante_1 = quartis[0]\n",
    "limite_quadrante_2 = quartis[1]\n",
    "limite_quadrante_3 = quartis[2]\n",
    "limite_quadrante_4 = float(\"inf\")  # O último quadrante vai até o infinito\n",
    "\n",
    "# Adicionar uma coluna \"Faixa de População\" ao DataFrame com base nos limites dos quadrantes\n",
    "df_pesquisa_final = df_pesquisa_final.withColumn(\"Faixa de População\",\n",
    "                                                when(col(\"populacional\") <= limite_quadrante_1, f\"Entre 0 e {int(limite_quadrante_1)}\")\n",
    "                                                .when((col(\"populacional\") > limite_quadrante_1) & (col(\"populacional\") <= limite_quadrante_2), f\"Entre {int(limite_quadrante_1)} e {int(limite_quadrante_2)}\")\n",
    "                                                .when((col(\"populacional\") > limite_quadrante_2) & (col(\"populacional\") <= limite_quadrante_3), f\"Entre {int(limite_quadrante_2)} e {int(limite_quadrante_3)}\")\n",
    "                                                .when((col(\"populacional\") > limite_quadrante_3) & (col(\"populacional\") <= limite_quadrante_4), f\"Maior que {int(limite_quadrante_3)}\")\n",
    "                                                .otherwise(\"Outro\"))\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "df_pesquisa_final.show()\n",
    "\n",
    "\n",
    "df_pesquisa_final.write.format(\"jdbc\").option(\"url\", gold_url) \\\n",
    ".option(\"user\", \"ibge\") \\\n",
    ".option(\"password\", \"ibge\") \\\n",
    ".option(\"dbtable\", \"public.fato_pesquisa\") \\\n",
    ".mode('overwrite') \\\n",
    ".save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4315c6e0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
